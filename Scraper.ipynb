{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import NoAlertPresentException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import sys\n",
    "\n",
    "import unittest, time, re,os,threading\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from settings import TWITTER_USERNAME,TWITTER_PASSWORD,GECKO_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.bbc.com/indonesia/trensosial-49880667\n",
    "hashtagProMahasiswa=[\"#kpkkuatkorupsiturun\", \"#KekuasaanDitanganRakyat\", \"#GejayanMemanggil2\", \"#diperkosanegara\", \"#mahasiswabergerak\", \"#hidupmahasiswa\", \"#tolakruukuhp\", \"#tolakrevisiuukpk\", \"#hiduprakyatindonesia\", \"#mositidakpercaya\", \"#reformasidikorupsi\", \"#stmmelawan\", \"#stmbergerak\", \"#gejayanmemanggil\", \"#indonesiaberduka\", \"#bebaskananandabadudu\", \"#BebaskanDandhyLaksono\", \"#savekpk\", \"#petisisavekpk\",\"#belajardaripelajar\",\"#rakyatbergerak\",\"#revisiuukpkfornkri\", \"#dukungrevisiuukpk\", \"#kpkcengeng\", \"#tempokacungkpk\", \"#kpkpatuhaturan\", \"#kpklebihbaik\", \"#sayabersamajokowi\", \"#jokowimendengarrakyat\", \"#kitadukungjokowi\",\"#percayalangkahjokowi\"]\n",
    "thisHashtag=hashtagProMahasiswa[30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = Firefox(executable_path=GECKO_PATH)\n",
    "wd.base_url = \"https://twitter.com/login\"\n",
    "wd.maximize_window()\n",
    "wd.get(wd.base_url)\n",
    "time.sleep(3)\n",
    "loginField = wd.find_element_by_class_name(\"js-username-field\")\n",
    "loginField.clear()\n",
    "loginField.send_keys(TWITTER_USERNAME)\n",
    "time.sleep(1)\n",
    "passwordField = wd.find_element_by_class_name(\"js-password-field\")\n",
    "passwordField.clear()\n",
    "passwordField.send_keys(TWITTER_PASSWORD)\n",
    "time.sleep(1)\n",
    "passwordField.submit()\n",
    "time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchField = wd.find_element_by_xpath(\"//input[@data-testid='SearchBox_Search_Input']\")\n",
    "searchField.clear()\n",
    "searchField.send_keys(thisHashtag)\n",
    "time.sleep(1)\n",
    "searchField.submit()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopCounter = 0\n",
    "lastHeight = wd.execute_script(\"return document.body.scrollHeight\")\n",
    "arrTweet=[]\n",
    "while True:\n",
    "    if loopCounter > 100:\n",
    "        print(loopCounter)\n",
    "    wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    newHeight = wd.execute_script(\"return document.body.scrollHeight\")\n",
    "    if newHeight == lastHeight:\n",
    "        print(\"break di newheight = lastheight\")\n",
    "        break\n",
    "    lastHeight = newHeight\n",
    "    loopCounter = loopCounter + 1\n",
    "    html_source = wd.page_source\n",
    "    sourcedata = html_source.encode('utf-8')\n",
    "    soup=bs(sourcedata)\n",
    "    arr = [x for x in soup.body.findAll('div', attrs={'data-testid':'tweet'})]\n",
    "    print(\"temp result : \" + str(len(arr)))\n",
    "    arrTweet.extend(arr)\n",
    "print('ended at: ' + str(loopCounter))\n",
    "print(\"Total : \" + str(len(arrTweet)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(soup):\n",
    "    #url,username,time\n",
    "    getUrlWithStatus = soup.select(\"a[href*=status]\")\n",
    "    if len(getUrlWithStatus)<=0:\n",
    "        print(\"sad\")\n",
    "    else:\n",
    "        _urlTweet.append(str(getUrlWithStatus[0][\"href\"]))\n",
    "        splitStatus = re.split('/',str(getUrlWithStatus[0][\"href\"]))\n",
    "        _username.append(\"@\"+splitStatus[1])\n",
    "        dateTime = getUrlWithStatus[0].find(\"time\")\n",
    "        if dateTime is not None:\n",
    "            _time.append(dateTime[\"datetime\"])\n",
    "        else:\n",
    "            _time.append('-')\n",
    "\n",
    "        #type,extrainfo\n",
    "        if len(soup.find_all(text=re.compile('Replying to'))) == 1:\n",
    "            _type.append('reply')\n",
    "            findTarget = soup.find(text=re.compile('Replying to')).parent\n",
    "            replyingTo = findTarget.find(\"span\")\n",
    "            if replyingTo is not None:\n",
    "                _extraInfoTargetUser.append(replyingTo.text)\n",
    "            else:\n",
    "                _extraInfoTargetUser.append('-')\n",
    "            _extraInfoContent.append('-')\n",
    "        elif len(soup.find_all(text=re.compile('Quote Tweet'))) == 1:\n",
    "            _type.append('quotereply')\n",
    "            try:\n",
    "                _extraInfoContent.append(str(getUrlWithStatus[1][\"href\"]))\n",
    "            except IndexError:\n",
    "                _extraInfoTargetUser.append('-')\n",
    "                _extraInfoContent.append('-')\n",
    "            else: \n",
    "                _extraInfoContent.append(str(getUrlWithStatus[1][\"href\"]))\n",
    "                splitStatus = re.split('/',str(getUrlWithStatus[1][\"href\"]))\n",
    "                _extraInfoTargetUser.append('@'+splitStatus[1])\n",
    "        else:\n",
    "            _type.append('tweet')\n",
    "            _extraInfoTargetUser.append('-')\n",
    "            _extraInfoContent.append('-')\n",
    "\n",
    "        #reply,retweet,likes\n",
    "        reply=0\n",
    "        retweet=0\n",
    "        likes =0\n",
    "        try:\n",
    "            divReply = soup.select(\"div[data-testid=reply]\")[0].text\n",
    "        except IndexError:\n",
    "            _reply.append('0')\n",
    "            reply=0\n",
    "        else:\n",
    "            if len(divReply.strip()) <= 0:\n",
    "                divReply = '0'\n",
    "                reply=0\n",
    "            elif 'K' in divReply:\n",
    "                print(\"banyak nih reply\")\n",
    "                divReply = divReply.strip('K')\n",
    "                newReply = float(divReply) * 1000\n",
    "                divReply = str(newReply)\n",
    "                divReply = divReply[:-2]\n",
    "                reply=divReply\n",
    "            else:\n",
    "                divReply = divReply.strip()\n",
    "                reply=divReply\n",
    "            print(\"Reply : \"+divReply)\n",
    "            _reply.append(divReply)\n",
    "\n",
    "        try:\n",
    "            divRetweet = soup.select(\"div[data-testid=retweet]\")[0].text\n",
    "        except IndexError:\n",
    "            retweet = 0\n",
    "            _retweet.append('0')\n",
    "        else:\n",
    "            if len(divRetweet.strip()) <= 0:\n",
    "                retweet = 0\n",
    "                divRetweet = '0'\n",
    "            elif 'K' in divRetweet:\n",
    "                print(\"banyak nih retweet\")\n",
    "                divRetweet = divRetweet.strip('K')\n",
    "                newRetweet = float(divRetweet) * 1000\n",
    "                divRetweet = str(newRetweet)\n",
    "                divRetweet = divRetweet[:-2]\n",
    "                retweet = divRetweet\n",
    "            else:\n",
    "                divRetweet = divRetweet.strip()\n",
    "                retweet = divRetweet\n",
    "            print(\"Retweet : \"+divRetweet)\n",
    "            _retweet.append(divRetweet)\n",
    "\n",
    "        try:\n",
    "            divLike = soup.select(\"div[data-testid=like]\")[0].text\n",
    "        except IndexError:\n",
    "            _like.append('0')\n",
    "            like=0\n",
    "        else:\n",
    "            if len(divLike.strip()) <= 0:\n",
    "                divLike = '0'\n",
    "                like=0\n",
    "            elif 'K' in divLike:\n",
    "                    print(\"banyak nih like\")\n",
    "                    divLike = divLike.strip('K')\n",
    "                    newLike = float(divLike) * 1000\n",
    "                    divLike = str(newLike)\n",
    "                    divLike = divLike[:-2]\n",
    "                    like=divLike\n",
    "            else:\n",
    "                divLike = divLike.strip()\n",
    "                like=divLike\n",
    "            print(\"Like : \"+divLike)\n",
    "            _like.append(divLike)\n",
    "        \n",
    "        #count max,total,weight\n",
    "        maxNum = max(float(like),float(retweet),float(reply))\n",
    "        total = float(like)+float(retweet)+float(reply)\n",
    "        weight=0\n",
    "        if maxNum > 0 and total > 0:\n",
    "            weight=maxNum/total\n",
    "        _total.append(str(total))\n",
    "        _max.append(str(maxNum))\n",
    "        _weight.append(str(weight))\n",
    "        print(\"Total : \"+str(total))\n",
    "        print(\"Max : \"+str(maxNum))\n",
    "        print(\"Weight : \"+str(weight))\n",
    "\n",
    "        #Content\n",
    "        hashtag = []\n",
    "        mention = []\n",
    "        urls = []\n",
    "        divContent = soup.select(\"div.css-901oao.r-hkyrab.r-1qd0xha.r-a023e6.r-16dba41.r-ad9z0x.r-bcqeeo.r-bnwqim.r-qvutc0\")\n",
    "        try:\n",
    "            textContent = divContent[0].text\n",
    "        except IndexError:\n",
    "            _content.append(\"-\")\n",
    "            _lang.append(\"-\")\n",
    "            urls.append(\"-\")\n",
    "            hashtag.append(\"-\")\n",
    "            mention.append(\"-\")\n",
    "            _hashtags.append(hashtag)\n",
    "            _mentions.append(mention)\n",
    "            _contentUrl.append(urls)\n",
    "        else:            \n",
    "            language = divContent[0][\"lang\"]\n",
    "            links = divContent[0].select(\"a\")\n",
    "            for l in links:\n",
    "                if '#' in l.text:\n",
    "                    hashtag.append(l.text)\n",
    "                elif '@' in l.text:\n",
    "                    mention.append(l.text)\n",
    "                elif 'photo' not in l[\"href\"]:\n",
    "                    if not l.find('title'):\n",
    "                        print(\"title sad\")\n",
    "                        urls.append(\"-\")\n",
    "                    else:\n",
    "                        urls.append(l[\"title\"])\n",
    "\n",
    "            _content.append(textContent)\n",
    "            _lang.append(language)\n",
    "            _hashtags.append(hashtag)\n",
    "            _mentions.append(mention)\n",
    "            _contentUrl.append(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_urlTweet=[]\n",
    "_username=[]\n",
    "_time=[]\n",
    "_type=[]\n",
    "_reply=[]\n",
    "_retweet=[]\n",
    "_like=[]\n",
    "_extraInfoTargetUser=[]\n",
    "_extraInfoContent=[]\n",
    "_content=[]\n",
    "_lang=[]\n",
    "_hashtags=[]\n",
    "_mentions=[]\n",
    "_contentUrl=[]\n",
    "_max=[]\n",
    "_total=[]\n",
    "_weight=[]\n",
    "dict = {\n",
    "    \"urlTweet\":_urlTweet,\n",
    "    \"username\":_username,\n",
    "    \"time\":_time,\n",
    "    \"type\":_type,\n",
    "    \"reply\":_reply,\n",
    "    \"retweet\":_retweet,\n",
    "    \"like\":_like,\n",
    "    \"extraInfoTargetUser\":_extraInfoTargetUser,\n",
    "    \"extraInfoContent\":_extraInfoContent,\n",
    "    \"content\":_content,\n",
    "    \"lang\":_lang,\n",
    "    \"hashtags\":_hashtags,\n",
    "    \"mentions\":_mentions,\n",
    "    \"contentUrl\":_contentUrl,\n",
    "    \"max\":_max,\n",
    "    \"total\":_total,\n",
    "    \"weight\":_weight\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for x in arrTweet:\n",
    "    print(\"Iter : \"+str(i))\n",
    "    sourcedata=x.encode('utf-8')\n",
    "    soup=bs(sourcedata)\n",
    "    extract(soup)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.DataFrame.from_dict(dict,orient='index').T \n",
    "main.to_csv(thisHashtag+'.csv')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('Sekarpramesi': virtualenv)",
   "language": "python",
   "name": "python37364bitsekarpramesivirtualenvb95a2fb76c754aa08b6ecdb9ac4dccd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}